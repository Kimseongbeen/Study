[의문  또는  제안] 
- 사물인식으로  person을  감지했을  때,  거리값을  알  수  없는데  어떻게  전달해주지?  일정  거
리값은  그냥  고정시켜  놓아야  하나? 
: 2d  카메라로  거리를  추론하는  AI를  구현한  경험이  있긴  함 
  (링크: https://blog.naver.com/112fkdldjs/223201279038 ) 


- 거리는  이미  정해졌다고  가정했을  때  내가  생각하는  교육  수준의  인식  알고리즘:  person 
발견  시  사람이  이미지  상의  y값  중앙이  될  수  있도록  로봇의  각도를  조정하고  사람이 
중간에  오는  순간  로봇이  바라보는  각도로  선을  그어서(고정해놓은  거리값만큼)  그  곳에 
사람이  있음을  Map에  표시 


- 개발은  파이썬으로  가능할  듯. ROS도  모두  파이썬인지? 
>인식해서 XYG,Z를 넘겨주는것을 파이썬으로 작성

빨리 개발할수 있고 편한언어로 하는게 좋을것 같다.


- 물체를  인식하는  코드  작성  시  주피터  노트북으로?  아니면  파이썬  코드로  class화  하여 
작성? 
➔ 교육하면서  설명하기에는  주피터  노트북이  최고이긴  하다 
>툴 통합

- 사물  인식  결과를  Nav2에  통합하는  과정에  대한  제안 
➔ 아직  ROS2  Nav2가  미숙하기  때문에, 이미지를  받아서  사물인식을  하고  return값으로 
미감지,  좌,  센터,  우  값을  반환하는  패키지를  제작하여  공유하면,  성삼우님이  그  패키
지를  import하여  Nav2에  합치는  과정  도움  필요! 
: YOLO  인식  패키지는  아래  처럼  만들어서  드릴  수  있을  것  같음 
  (링크: https://github.com/Nyan-SouthKorea/RealSense_YOLOv7-Package/blob/main/custom_yolov7_inference.py ) 
➔ Return값  설명 
:  미감지  = person이  아직  감지되지  않았음 
:  좌  = person이  왼쪽에  있음.  로봇을  왼쪽으로  회전해야  하는  상황임. 
:  우  = person이  우측에  있음.  로봇을  우측으로  회전해야  하는  상황임. 
- 기타  제안:  이  강의의  컨셉이  ROS만을  배우기  위한  강의라면,  이대로  진행하면  좋음.  하
지만  AI관련  지식도  같이  얻길  원하는  강의라면  사람을  감지하지  말고  자신이  원하는  사
물  사진을  30장  찍어서  직접  학습하여  감지하는  과정을  넣을  수  있음.  이렇게  되면  사물
인식  강의  파트가  조금  길어질  수는  있음

코코데이터셋 알려진것이 있어서 몰라도

시나리오에서
이런사물들을 인식할수 있다.

이미지 인퍼런스 하는

YOLO 제일 가벼운 모델 cpu마다 5~10 fps

카메라는 30 hz, 하지만 해당 프로젝트는

1초에 5~10초만 감지하면 될것같아서

21분 부분쯤에 통신 뚫어주는것

황당한 일화 - 시나리오


라이언 -  YOLO 모델에 대한 설명, 오브젝트 디텍션이 어떤 느낌인지 설명, CNN 딥러닝 필요 X 강의도 3개로 나눠서 짧게
김성빈 -  라이언님이 오브젝트 디텍션이란? 최대한 평범한 사람들이 이해할수 있게 - 25분
진짜 간단하게만 설명 - 용어에 대해 설명- 어디에 쓰이는지 설명 - 모델이름이 31분. 예시 :32분

어떻게 만들건데의 구상이 어떤지 

배운점: 강의의 신념이 있으면 그대로 따라가겠다. 없다면 제가 만들겟지만 - 29분 이런생각은 자연스럽게하지 못했다.

가제보 - 

41분- 제목, 소제목, 여기에서 이렇게 어떻게 설명할건지에 대한 간단하게 몇줄 작성

